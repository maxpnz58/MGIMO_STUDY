{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Работа с модулем Pandas\n",
    "\n",
    "Модуль Pandas предназначен для работы с данными, чем-то напоминающей работу с электронными таблицами. Данные хранятся в таблице с именованными колонками и пронумерованными строками.\n",
    "\n",
    "Для начала подключим модуль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данная конструкция подключает модуль pandas\n",
    "# и позволяет обращаться к его функциям через имя pd.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение данных с помощью Pandas\n",
    "\n",
    "Вероятно, один из наиболее часто встречающихся видов работы по анализу данных это чтение данных. Библиотека pandas предлагает  функции для чтения и записи файлов в различных форматах, таких как CSV, JSON, XML и XLSX Excel, причем все они создают DataFrame с информацией, считанной из файла.\n",
    "\n",
    "Существует множество доступных функций чтения, как показано в следующей таблице:\n",
    "\n",
    "![pandas read data table](https://raw.githubusercontent.com/yakushinav/omo/afc79fcda09f4abc49dc15ac8b6d0eec943d5dd1/img/pandas_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод `read_csv`\n",
    "\n",
    "Первый метод, который мы изучим, — это **read_csv**, который позволяет нам считывать файлы со значениями, разделенными запятыми (CSV) и файлы необработанного текста (TXT) в DataFrame.\n",
    "\n",
    "Функция `read_csv` чрезвычайно мощна, и вы можете указать очень широкий набор параметров во время импорта, что позволяет нам точно настроить способ чтения и анализа данных, указав правильную структуру, кодирование и другие детали. Наиболее распространенные параметры следующие:\n",
    "\n",
    "- `filepath`: путь к файлу, который нужно прочитать.\n",
    "- `sep`: символы, которые используются в качестве разделителя полей в файле.\n",
    "- `header`: индекс строки, содержащей имена столбцов (нет, если нет).\n",
    "- `index_col`: индекс столбца или последовательности индексов, которые следует использовать в качестве индекса строк данных.\n",
    "- `names`: последовательность, содержащая имена столбцов (используется вместе с заголовком = None).\n",
    "- `skiprows`: количество строк или последовательность индексов строк, которые следует игнорировать при загрузке.\n",
    "- `na_values`: последовательность значений, которые, если они найдены в файле, должны рассматриваться как NaN.\n",
    "- `dtype`: словарь, в котором ключами будут имена столбцов, а значениями будут типы NumPy, в которые должно быть преобразовано их содержимое.\n",
    "- `parse_dates`: флаг, указывающий, должен ли Python попытаться проанализировать данные в формате, аналогичном датам, как даты. Вы можете ввести список имен столбцов, которые необходимо объединить для анализа, в качестве даты.\n",
    "- `date_parser`: функция, которую можно использовать для анализа дат.\n",
    "- `nrows`: количество строк для чтения с начала файла.\n",
    "- `skip_footer`: количество строк, которые нужно игнорировать в конце файла.\n",
    "- `encoding`: ожидаемая кодировка прочитанного файла.\n",
    "- `squeeze`: флаг, указывающий, что если считанные данные содержат только один столбец, результатом будет серия, а не DataFrame.\n",
    "- `тысячи`: символ, используемый для определения разделителя тысяч.\n",
    "- `decimal`: символ, используемый для определения десятичного разделителя.\n",
    "- `skip_blank_lines`: флаг, указывающий, следует ли игнорировать пустые строки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение нашего первого файла CSV\n",
    "\n",
    "Каждый раз, когда мы вызываем метод read_csv, нам нужно будет передать явный параметр filepath, указывающий путь, где находится наш CSV-файл.\n",
    "\n",
    "Допускается любой допустимый путь к строке. Строка может быть URL-адресом. Допустимые схемы URL-адресов включают HTTP, FTP, S3 и файл. Для URL-адресов файлов ожидается хост. Локальным файлом может быть: `file://localhost/path/to/table.csv`.\n",
    "\n",
    "Например, мы можем использовать метод read_csv для загрузки данных непосредственно из URL-адреса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_url = \"https://raw.githubusercontent.com/yakushinav/omo/main/data/gdp.csv\"\n",
    "\n",
    "pd.read_csv(csv_url).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Рассмотрим набор данных, о ценах акций (на самом деле тут не важно каких)\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/market-price.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поведение первой строки с параметром `header`\n",
    "\n",
    "В CSV-файле, который мы читаем, есть только два столбца: Timestamp и Price. У него нет заголовка. Pandas автоматически назначил первую строку данных в качестве заголовков, что неверно. Мы можем перезаписать это поведение с помощью параметра «header»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/market-price.csv',\n",
    "                 header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметр `na_values` для отсутствующих значений\n",
    "\n",
    "Мы можем определить параметр na_values со значениями, которые мы хотим распознавать как NA/NaN. В этом случае пустые строки `''`, `?` и `-` будут распознаваться как нулевые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/market-price.csv',\n",
    "                 header=None,\n",
    "                 na_values=['', '?', '-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Параметр `names` для имен столбцов (полей данных)\n",
    "\n",
    "Мы добавим имена этих столбцов, используя параметр «names»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/market-price.csv',\n",
    "                 header=None,\n",
    "                 na_values=['', '?', '-'],\n",
    "                 names=['Timestamp', 'Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типы столбцов с использованием параметра `dtype`\n",
    "\n",
    "\n",
    "Без использования параметра dtype Pandas попытаются автоматически определить тип каждого столбца. Мы можем использовать параметр dtype, чтобы указать Pandas использовать определенный тип dtype.\n",
    "\n",
    "В этом случае мы заставим столбец «Цена» иметь значение с плавающей запятой (вещественное число)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/market-price.csv',\n",
    "                 header=None,\n",
    "                 na_values=['', '?', '-'],\n",
    "                 names=['Timestamp', 'Price'],\n",
    "                 dtype={'Price': 'float'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Столбец Timestamp интерпретируется как обычная строка («object» в нотации pandas).\n",
    "\n",
    "Мы преобразуем столбец Timestamp в объекты Datetime, используя метод to_datetime:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['Timestamp']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование даты с использованием параметра `parse_dates`\n",
    "\n",
    "Другой способ работы с объектами Datetime — использование параметра parse_dates с указанием положения столбцов с датами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/market-price.csv',\n",
    "                 header=None,\n",
    "                 na_values=['', '?', '-'],\n",
    "                 names=['Timestamp', 'Price'],\n",
    "                 dtype={'Price': 'float'},\n",
    "                 parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление индекса с помощью параметра index_col\n",
    "\n",
    "По умолчанию pandas автоматически назначает числовой автоинкрементный индекс или метку строки, начинающуюся с нуля. Возможно, вы захотите оставить индекс по умолчанию как таковой, если в ваших данных нет столбца с уникальными значениями, который мог бы служить лучшим индексом. Если есть столбец, который, по вашему мнению, будет служить лучшим индексом, вы можете переопределить поведение по умолчанию, установив для столбца свойство index_col. Он принимает числовое значение, представляющее индекс, или строку имени столбца для установки одного столбца в качестве индекса или список числовых значений или строк для создания мультииндекса.\n",
    "\n",
    "В наших данных мы выбираем первый столбец Timestamp в качестве индекса (index=0), передавая ноль в аргумент index_col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/market-price.csv',\n",
    "                 header=None,\n",
    "                 na_values=['', '?', '-'],\n",
    "                 names=['Timestamp', 'Price'],\n",
    "                 dtype={'Price': 'float'},\n",
    "                 parse_dates=[0],\n",
    "                 index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чуть более сложный пример чтения данных\n",
    "\n",
    "Теперь мы прочитаем еще один файл CSV. Этот файл имеет следующие столбцы:\n",
    "\n",
    "- `first_name`\n",
    "- `last_name`\n",
    "- `age`\n",
    "- `math_score`\n",
    "- `french_score`\n",
    "- `next_test_date`\n",
    "\n",
    "Давайте прочитаем и посмотрим, как это выглядит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exam_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пользовательские разделители данных с использованием параметра `sep`\n",
    "\n",
    "Мы можем определить, какой разделитель использовать, используя параметр `sep`. Если мы не используем параметр `sep`, pandas автоматически обнаружит разделитель.\n",
    "\n",
    "В большинстве файлов CSV разделителем является запятая (`,`) и он определяется автоматически. Но мы можем найти файлы с другими разделителями, такими как точка с запятой (`;`), табуляция (`\\t`, особенно в файлах TSV), пробелы или любые другие специальные символы.\n",
    "\n",
    "В этом случае разделителем является символ `>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "                      sep='>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exam_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодировка данных\n",
    "\n",
    "Файлы хранятся с использованием разных «кодировок». Вы, наверное, слышали об ASCII, UTF-8, cp1251 и т.д.\n",
    "\n",
    "При чтении данных пользовательскую кодировку можно определить с помощью параметра encoding.\n",
    "\n",
    "- `encoding='UTF-8'`: будет использоваться, если данные закодированы UTF-8.\n",
    "- `encoding='cp1251'`: будет использоваться, если данные закодированы в соответствии с windows cp1251.\n",
    "\n",
    "В нашем случае нам не нужна специальная кодировка, поскольку данные загружаются правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изменение разделителя «десятичный» и «тысячный».\n",
    "\n",
    "Десятичные и тысячные знаки символов могут меняться в разных наборах данных. Если у нас есть столбец, содержащий запятую (`,`) для обозначения десятичного знака или знака тысяч, тогда этот столбец будет считаться строкой, а не числовым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "                      sep='>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df[['math_score', 'french_score']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы решить эту проблему и гарантировать, что такие столбцы интерпретируются как целочисленные значения, нам нужно будет использовать параметры «decimal» и/или «thousands», чтобы указать правильные десятичные и/или тысячи индикаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "                      sep='>',\n",
    "                      decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df[['math_score', 'french_score']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим, что происходит с параметром «thousands»:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "            sep='>',\n",
    "            thousands=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исключение определенных строк\n",
    "\n",
    "Мы можем использовать `skiprows`, чтобы:\n",
    "\n",
    "— Исключить чтение указанного количества строк из начала файла, передав целочисленный аргумент. **При этом также будет удален заголовок**.\n",
    "— Пропустить чтение определенных индексов строк из файла, передав список, содержащий индексы строк, которые нужно пропустить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "                      sep='>',\n",
    "                      decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы пропустить чтение первых двух строк из этого файла, мы можем использовать skiprows=2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "            sep='>',\n",
    "            skiprows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку заголовок считается первой строкой, чтобы пропустить чтение строк данных 1 и 3, мы можем использовать skiprows=[1,3]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "                      sep='>',\n",
    "                      decimal=',',\n",
    "                      skiprows=[1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Избавьтесь от пустых строк\n",
    "\n",
    "Для параметра skip_blank_lines установлено значение True, поэтому пустые строки пропускаются при чтении файлов.\n",
    "\n",
    "Если мы установим для этого параметра значение False, то каждая пустая строка будет загружена со значениями NaN в DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "            sep='>',\n",
    "            skip_blank_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка определенных столбцов\n",
    "\n",
    "Мы можем использовать параметр usecols, когда хотим загрузить только определенные столбцы, а не все.\n",
    "\n",
    "С точки зрения производительности это лучше, потому что вместо загрузки всех данных в память, а затем удаления ненужных столбцов, мы можем выбрать нужные столбцы, загружая сам набор данных.\n",
    "\n",
    "В качестве параметра usecols вы можете передать либо список строк, соответствующих именам столбцов, либо список целых чисел, соответствующих индексу столбца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "            usecols=['first_name', 'last_name', 'age'],\n",
    "            sep='>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или используя только позицию столбца:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "            usecols=[0, 1, 2],\n",
    "            sep='>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование `Series` вместо `DataFrame`\n",
    "\n",
    "Если проанализированные данные содержат только один столбец, мы можем вернуть ряд данных, используя метод «squeeze»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_test_1 = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "                          sep='>',\n",
    "                          usecols=['last_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(exam_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_test_2 = pd.read_csv('https://raw.githubusercontent.com/yakushinav/omo/main/data/exam_review.csv',\n",
    "                          sep='>',\n",
    "                          usecols=['last_name']).squeeze('columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(exam_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранить в файл CSV\n",
    "\n",
    "Мы также можем сохранить наш DataFrame в виде файла CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем просто сгенерировать строку CSV из нашего DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или укажите путь к файлу, в котором мы хотим сохранить сгенерированный код CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exam_df.to_csv('out.csv',\n",
    "               index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
